{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries for Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define function to be used across sections below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_from_list(values_list):\n",
    "    values_string = \"\"\n",
    "    if(len(values_list) > 0):\n",
    "        for i in range(len(values_list)):  \n",
    "            values_string = str(values_string) + str(values_list[i]) + \",\"\n",
    "    else:\n",
    "        values_string = \"None \"\n",
    "    return values_string[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import tweets gathered for each of 3 hurricances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "florence_df = pd.read_csv(\"../Data/florence_clean.csv\")\n",
    "harvey_df = pd.read_csv(\"../Data/harvey_clean.csv\")\n",
    "michael_df = pd.read_csv(\"../Data/michael_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>state</th>\n",
       "      <th>split_text</th>\n",
       "      <th>closed</th>\n",
       "      <th>open</th>\n",
       "      <th>cause</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, username, date, text, time, state, split_text, closed, open, cause]\n",
       "Index: []"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harvey_df[harvey_df[\"text\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvey_df[\"text\"].fillna(\"\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "florence_df[\"text\"].fillna(\"\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "michael_df[\"text\"].fillna(\"\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for Non-Highway Roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in gathered road suffix data\n",
    "road_suffix_df = pd.read_csv(\"../Data/Road_Suffix_List.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of key suffixes and lowercase them\n",
    "suffix_list = list(set(road_suffix_df[\"Primary Street Name\"].str.lower().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary with keys as each suffix and values as list of abbreviations for that suffix\n",
    "suffix_dict = {}\n",
    "for roads in road_suffix_df.index:\n",
    "    name = road_suffix_df.loc[roads, \"Primary Street Name\"]\n",
    "    suffix_dict[name] = road_suffix_df[road_suffix_df[\"Primary Street Name\"] == name][\"Abbreviations\"].str.lower().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing suffixes as needed\n",
    "suffix_dict[\"ROUTE\"] = [\"route\", \"rte\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALLEY': ['allee', 'alley', 'ally', 'aly'],\n",
       " 'ANEX': ['anex', 'annex', 'annx', 'anx'],\n",
       " 'ARCADE': ['arc', 'arcade'],\n",
       " 'AVENUE': ['av', 'ave', 'aven', 'avenu', 'avenue', 'avn', 'avnue'],\n",
       " 'BAYOU': ['bayoo', 'bayou'],\n",
       " 'BEACH': ['bch', 'beach'],\n",
       " 'BEND': ['bend', 'bnd'],\n",
       " 'BLUFF': ['blf', 'bluf', 'bluff'],\n",
       " 'BLUFFS': ['bluffs'],\n",
       " 'BOTTOM': ['bot', 'btm', 'bottm', 'bottom'],\n",
       " 'BOULEVARD': ['blvd', 'boul', 'boulevard', 'boulv'],\n",
       " 'BRANCH': ['br', 'brnch', 'branch'],\n",
       " 'BRIDGE': ['brdge', 'brg', 'bridge'],\n",
       " 'BROOK': ['brk', 'brook'],\n",
       " 'BROOKS': ['brooks'],\n",
       " 'BURG': ['burg'],\n",
       " 'BURGS': ['burgs'],\n",
       " 'BYPASS': ['byp', 'bypa', 'bypas', 'bypass', 'byps'],\n",
       " 'CAMP': ['camp', 'cp', 'cmp'],\n",
       " 'CANYON': ['canyn', 'canyon', 'cnyn'],\n",
       " 'CAPE': ['cape', 'cpe'],\n",
       " 'CAUSEWAY': ['causeway', 'causwa', 'cswy'],\n",
       " 'CENTER': ['cen',\n",
       "  'cent',\n",
       "  'center',\n",
       "  'centr',\n",
       "  'centre',\n",
       "  'cnter',\n",
       "  'cntr',\n",
       "  'ctr'],\n",
       " 'CENTERS': ['centers'],\n",
       " 'CIRCLE': ['cir', 'circ', 'circl', 'circle', 'crcl', 'crcle'],\n",
       " 'CIRCLES': ['circles'],\n",
       " 'CLIFF': ['clf', 'cliff'],\n",
       " 'CLIFFS': ['clfs', 'cliffs'],\n",
       " 'CLUB': ['clb', 'club'],\n",
       " 'COMMON': ['common'],\n",
       " 'COMMONS': ['commons'],\n",
       " 'CORNER': ['cor', 'corner'],\n",
       " 'CORNERS': ['corners', 'cors'],\n",
       " 'COURSE': ['course', 'crse'],\n",
       " 'COURT': ['court', 'ct'],\n",
       " 'COURTS': ['courts', 'cts'],\n",
       " 'COVE': ['cove', 'cv'],\n",
       " 'COVES': ['coves'],\n",
       " 'CREEK': ['creek', 'crk'],\n",
       " 'CRESCENT': ['crescent', 'cres', 'crsent', 'crsnt'],\n",
       " 'CREST': ['crest'],\n",
       " 'CROSSING': ['crossing', 'crssng', 'xing'],\n",
       " 'CROSSROAD': ['crossroad'],\n",
       " 'CROSSROADS': ['crossroads'],\n",
       " 'CURVE': ['curve'],\n",
       " 'DALE': ['dale', 'dl'],\n",
       " 'DAM': ['dam', 'dm'],\n",
       " 'DIVIDE': ['div', 'divide', 'dv', 'dvd'],\n",
       " 'DRIVE': ['dr', 'driv', 'drive', 'drv'],\n",
       " 'DRIVES': ['drives'],\n",
       " 'ESTATE': ['est', 'estate'],\n",
       " 'ESTATES': ['estates', 'ests'],\n",
       " 'EXPRESSWAY': ['exp', 'expr', 'express', 'expressway', 'expw', 'expy'],\n",
       " 'EXTENSION': ['ext', 'extension', 'extn', 'extnsn'],\n",
       " 'EXTENSIONS': ['exts'],\n",
       " 'FALL': ['fall'],\n",
       " 'FALLS': ['falls', 'fls'],\n",
       " 'FERRY': ['ferry', 'frry', 'fry'],\n",
       " 'FIELD': ['field', 'fld'],\n",
       " 'FIELDS': ['fields', 'flds'],\n",
       " 'FLAT': ['flat', 'flt'],\n",
       " 'FLATS': ['flats', 'flts'],\n",
       " 'FORD': ['ford', 'frd'],\n",
       " 'FORDS': ['fords'],\n",
       " 'FOREST': ['forest', 'forests', 'frst'],\n",
       " 'FORGE': ['forg', 'forge', 'frg'],\n",
       " 'FORGES': ['forges'],\n",
       " 'FORK': ['fork', 'frk'],\n",
       " 'FORKS': ['forks', 'frks'],\n",
       " 'FORT': ['fort', 'frt', 'ft'],\n",
       " 'FREEWAY': ['freeway', 'freewy', 'frway', 'frwy', 'fwy'],\n",
       " 'GARDEN': ['garden', 'gardn', 'grden', 'grdn'],\n",
       " 'GARDENS': ['gardens', 'gdns', 'grdns'],\n",
       " 'GATEWAY': ['gateway', 'gatewy', 'gatway', 'gtway', 'gtwy'],\n",
       " 'GLEN': ['glen', 'gln'],\n",
       " 'GLENS': ['glens'],\n",
       " 'GREEN': ['green', 'grn'],\n",
       " 'GREENS': ['greens'],\n",
       " 'GROVE': ['grov', 'grove', 'grv'],\n",
       " 'GROVES': ['groves'],\n",
       " 'HARBOR': ['harb', 'harbor', 'harbr', 'hbr', 'hrbor'],\n",
       " 'HARBORS': ['harbors'],\n",
       " 'HAVEN': ['haven', 'hvn'],\n",
       " 'HEIGHTS': ['ht', 'hts'],\n",
       " 'HIGHWAY': ['highway', 'highwy', 'hiway', 'hiwy', 'hway', 'hwy'],\n",
       " 'HILL': ['hill', 'hl'],\n",
       " 'HILLS': ['hills', 'hls'],\n",
       " 'HOLLOW': ['hllw', 'hollow', 'hollows', 'holw', 'holws'],\n",
       " 'INLET': ['inlt'],\n",
       " 'ISLAND': ['is', 'island', 'islnd'],\n",
       " 'ISLANDS': ['islands', 'islnds', 'iss'],\n",
       " 'ISLE': ['isle', 'isles'],\n",
       " 'JUNCTION': ['jct', 'jction', 'jctn', 'junction', 'junctn', 'juncton'],\n",
       " 'JUNCTIONS': ['jctns', 'jcts', 'junctions'],\n",
       " 'KEY': ['key', 'ky'],\n",
       " 'KEYS': ['keys', 'kys'],\n",
       " 'KNOLL': ['knl', 'knol', 'knoll'],\n",
       " 'KNOLLS': ['knls', 'knolls'],\n",
       " 'LAKE': ['lk', 'lake'],\n",
       " 'LAKES': ['lks', 'lakes'],\n",
       " 'LAND': ['land'],\n",
       " 'LANDING': ['landing', 'lndg', 'lndng'],\n",
       " 'LANE': ['lane', 'ln'],\n",
       " 'LIGHT': ['lgt', 'light'],\n",
       " 'LIGHTS': ['lights'],\n",
       " 'LOAF': ['lf', 'loaf'],\n",
       " 'LOCK': ['lck', 'lock'],\n",
       " 'LOCKS': ['lcks', 'locks'],\n",
       " 'LODGE': ['ldg', 'ldge', 'lodg', 'lodge'],\n",
       " 'LOOP': ['loop', 'loops'],\n",
       " 'MALL': ['mall'],\n",
       " 'MANOR': ['mnr', 'manor'],\n",
       " 'MANORS': ['manors', 'mnrs'],\n",
       " 'MEADOW': ['meadow'],\n",
       " 'MEADOWS': ['mdw', 'mdws', 'meadows', 'medows'],\n",
       " 'MEWS': ['mews'],\n",
       " 'MILL': ['mill'],\n",
       " 'MILLS': ['mills'],\n",
       " 'MISSION': ['missn', 'mssn'],\n",
       " 'MOTORWAY': ['motorway'],\n",
       " 'MOUNT': ['mnt', 'mt', 'mount'],\n",
       " 'MOUNTAIN': ['mntain', 'mntn', 'mountain', 'mountin', 'mtin', 'mtn'],\n",
       " 'MOUNTAINS': ['mntns', 'mountains'],\n",
       " 'NECK': ['nck', 'neck'],\n",
       " 'ORCHARD': ['orch', 'orchard', 'orchrd'],\n",
       " 'OVAL': ['oval', 'ovl'],\n",
       " 'OVERPASS': ['overpass'],\n",
       " 'PARK': ['park', 'prk'],\n",
       " 'PARKS': ['parks'],\n",
       " 'PARKWAY': ['parkway', 'parkwy', 'pkway', 'pkwy', 'pky'],\n",
       " 'PARKWAYS': ['parkways', 'pkwys'],\n",
       " 'PASS': ['pass'],\n",
       " 'PASSAGE': ['passage'],\n",
       " 'PATH': ['path', 'paths'],\n",
       " 'PIKE': ['pike', 'pikes'],\n",
       " 'PINE': ['pine'],\n",
       " 'PINES': ['pines', 'pnes'],\n",
       " 'PLACE': ['pl'],\n",
       " 'PLAIN': ['plain', 'pln'],\n",
       " 'PLAINS': ['plains', 'plns'],\n",
       " 'PLAZA': ['plaza', 'plz', 'plza'],\n",
       " 'POINT': ['point', 'pt'],\n",
       " 'POINTS': ['points', 'pts'],\n",
       " 'PORT': ['port', 'prt'],\n",
       " 'PORTS': ['ports', 'prts'],\n",
       " 'PRAIRIE': ['pr', 'prairie', 'prr'],\n",
       " 'RADIAL': ['rad', 'radial', 'radiel', 'radl'],\n",
       " 'RAMP': ['ramp'],\n",
       " 'RANCH': ['ranch', 'ranches', 'rnch', 'rnchs'],\n",
       " 'RAPID': ['rapid', 'rpd'],\n",
       " 'RAPIDS': ['rapids', 'rpds'],\n",
       " 'REST': ['rest', 'rst'],\n",
       " 'RIDGE': ['rdg', 'rdge', 'ridge'],\n",
       " 'RIDGES': ['rdgs', 'ridges'],\n",
       " 'RIVER': ['riv', 'river', 'rvr', 'rivr'],\n",
       " 'ROAD': ['rd', 'road'],\n",
       " 'ROADS': ['roads', 'rds'],\n",
       " 'ROUTE': ['route', 'rte'],\n",
       " 'ROW': ['row'],\n",
       " 'RUE': ['rue'],\n",
       " 'RUN': ['run'],\n",
       " 'SHOAL': ['shl', 'shoal'],\n",
       " 'SHOALS': ['shls', 'shoals'],\n",
       " 'SHORE': ['shoar', 'shore', 'shr'],\n",
       " 'SHORES': ['shoars', 'shores', 'shrs'],\n",
       " 'SKYWAY': ['skyway'],\n",
       " 'SPRING': ['spg', 'spng', 'spring', 'sprng'],\n",
       " 'SPRINGS': ['spgs', 'spngs', 'springs', 'sprngs'],\n",
       " 'SPUR': ['spur'],\n",
       " 'SPURS': ['spurs'],\n",
       " 'SQUARE': ['sq', 'sqr', 'sqre', 'squ', 'square'],\n",
       " 'SQUARES': ['sqrs', 'squares'],\n",
       " 'STATION': ['sta', 'station', 'statn', 'stn'],\n",
       " 'STRAVENUE': ['stra',\n",
       "  'strav',\n",
       "  'straven',\n",
       "  'stravenue',\n",
       "  'stravn',\n",
       "  'strvn',\n",
       "  'strvnue'],\n",
       " 'STREAM': ['stream', 'streme', 'strm'],\n",
       " 'STREET': ['street', 'strt', 'st', 'str'],\n",
       " 'STREETS': ['streets'],\n",
       " 'SUMMIT': ['smt', 'sumit', 'sumitt', 'summit'],\n",
       " 'TERRACE': ['ter', 'terr', 'terrace'],\n",
       " 'THROUGHWAY': ['throughway'],\n",
       " 'TRACE': ['trace', 'traces', 'trce'],\n",
       " 'TRACK': ['track', 'tracks', 'trak', 'trk', 'trks'],\n",
       " 'TRAFFICWAY': ['trafficway'],\n",
       " 'TRAIL': ['trail', 'trails', 'trl', 'trls'],\n",
       " 'TRAILER': ['trailer', 'trlr', 'trlrs'],\n",
       " 'TUNNEL': ['tunel', 'tunl', 'tunls', 'tunnel', 'tunnels', 'tunnl'],\n",
       " 'TURNPIKE': ['trnpk', 'turnpike', 'turnpk'],\n",
       " 'UNDERPASS': ['underpass'],\n",
       " 'UNION': ['un', 'union'],\n",
       " 'UNIONS': ['unions'],\n",
       " 'VALLEY': ['valley', 'vally', 'vlly', 'vly'],\n",
       " 'VALLEYS': ['valleys', 'vlys'],\n",
       " 'VIADUCT': ['vdct', 'via', 'viadct', 'viaduct'],\n",
       " 'VIEW': ['view', 'vw'],\n",
       " 'VIEWS': ['views', 'vws'],\n",
       " 'VILLAGE': ['vill', 'villag', 'village', 'villg', 'villiage', 'vlg'],\n",
       " 'VILLAGES': ['villages', 'vlgs'],\n",
       " 'VILLE': ['ville', 'vl'],\n",
       " 'VISTA': ['vis', 'vist', 'vista', 'vst', 'vsta'],\n",
       " 'WALK': ['walk'],\n",
       " 'WALKS': ['walks'],\n",
       " 'WALL': ['wall'],\n",
       " 'WAY': ['wy', 'way'],\n",
       " 'WAYS': ['ways'],\n",
       " 'WELL': ['well'],\n",
       " 'WELLS': ['wells', 'wls']}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function that searches through entire tweet for presence of any road suffix.\n",
    "# If a suffix is found, this function attempts to create the full road name by lookin at words that precede the suffix.\n",
    "# Specifically, road names are added with 1, 2, and 3 prior words\n",
    "# All road possibilities are added to a list and returned\n",
    "def check_other_roads(text, suffix_dict):\n",
    "    roads_list = []\n",
    "    words_list = text.split()\n",
    "    for i in range(len(words_list)):    \n",
    "        for suffix, abbrevs in suffix_dict.items():\n",
    "            for abbrev in abbrevs:\n",
    "                if abbrev in words_list[i]:\n",
    "                    if(len(words_list[i]) == len(abbrev)):\n",
    "                        if i > 0:\n",
    "                            roads_list.append(words_list[i-1] + \n",
    "                                                  \" \" + \n",
    "                                                  suffix.lower())\n",
    "                        if i > 1:\n",
    "                            roads_list.append(words_list[i-2] + \n",
    "                                                  \" \" + \n",
    "                                                  words_list[i-1] + \n",
    "                                                  \" \" + \n",
    "                                                  suffix.lower())\n",
    "                    elif((words_list[i].find(abbrev) + len(abbrev)) == len(words_list[i])):\n",
    "                        first_word = words_list[i].replace(abbrev, \"\")\n",
    "                        roads_list.append(first_word + \n",
    "                                                  \" \" + \n",
    "                                                  suffix.lower())\n",
    "                        if i > 0:\n",
    "                            roads_list.append(words_list[i-1] + \n",
    "                                                  \" \" + \n",
    "                                                  first_word + \n",
    "                                                  \" \" + \n",
    "                                                  suffix.lower())\n",
    "    return roads_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that loops through a dataframe and used above function to add strings of road possibilities to each tweet\n",
    "def add_other_road_features(df):\n",
    "    road_string_list = []\n",
    "    for rows in df.index:\n",
    "        text = df.loc[rows,\"text\"]\n",
    "        roads = check_other_roads(text, suffix_dict)\n",
    "        road_string_list.append(string_from_list(roads))\n",
    "    return road_string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvey_other_roads = pd.DataFrame()\n",
    "harvey_other_roads[\"Other_Road_List\"] = add_other_road_features(harvey_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvey_other_roads.to_csv(\"../Data/harvey_other_roads.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "florence_other_roads = pd.DataFrame()\n",
    "florence_other_roads[\"Other_Road_List\"] = add_other_road_features(florence_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "florence_other_roads.to_csv(\"../Data/florence_other_roads.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "michael_other_roads = pd.DataFrame()\n",
    "michael_other_roads[\"Other_Road_List\"] = add_other_road_features(michael_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "michael_other_roads.to_csv(\"../Data/michael_other_roads.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for exit numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exit_search(text):\n",
    "    words = text.split()\n",
    "    exit_string = \"\"\n",
    "    exit_list = []\n",
    "    for i in range(len(words)):\n",
    "        string = \"\"\n",
    "        if(((words[i] == \"exit\") |  (words[i] == \"ex\")) &\n",
    "           (i < len(words) - 1)):\n",
    "            try:\n",
    "                float(words[i+1][0])\n",
    "                string = \"exit \" + words[i+1]\n",
    "            except:\n",
    "                pass\n",
    "        elif((\"exit\" in words[i]) & (words[i].find(\"exit\") == 0)):\n",
    "            num_check = words[i].replace(\"exit\", \"\")\n",
    "            try:\n",
    "                float(num_check[0])\n",
    "                string = \"exit \" + num_check \n",
    "            except:\n",
    "                pass\n",
    "        elif((\"ex\" in words[i]) & (words[i].find(\"ex\") == 0)):\n",
    "            num_check = words[i].replace(\"ex\", \"\")\n",
    "            try:\n",
    "                float(num_check[0])\n",
    "                string = \"exit \" + num_check \n",
    "            except:\n",
    "                pass\n",
    "        if string != \"\":\n",
    "            exit_list.append(string)\n",
    "    return string_from_list(exit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_exit_lists(df):\n",
    "    exits_df = pd.DataFrame()\n",
    "    for row in df.index:\n",
    "        text = df.loc[row, \"text\"]\n",
    "        exits_df.loc[row, \"exit_list\"] = exit_search(text)\n",
    "    return exits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvey_exits = add_exit_lists(harvey_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exit_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>exit 845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>exit 845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>exit 845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>exit 335b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     exit_list\n",
       "270   exit 845\n",
       "308   exit 845\n",
       "365   exit 845\n",
       "868  exit 335b"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harvey_exits[(harvey_exits[\"exit_list\"] != \"None\") & (\"exit\" not in harvey_df[\"text\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270    closed due to high water in #chambers on i-10 ...\n",
      "308    closed due to high water in #chambers on i-10 ...\n",
      "365    closed due to high water in #chambers on i-10 ...\n",
      "868    #waco ih 35 sb at exit 335b shutdown for major...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(harvey_df[(harvey_exits[\"exit_list\"] != \"None\") & (\"exit\" not in harvey_df[\"text\"])][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvey_exits.to_csv(\"../Data/harvey_exits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "michael_exits = add_exit_lists(michael_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exit_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exit 10a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>exit 10a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>exit 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>exit 152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>exit 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>exit 45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>exit 152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>exit 45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>exit 10a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>exit 13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>exit 13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>exit 45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>exit 45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>exit 10a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>exit 174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>exit 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>exit 120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>exit 13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>exit 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>exit 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>exit 166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>exit 166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>exit 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>exit 130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>exit 45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>exit 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>exit 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>exit 28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>exit 28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>exit 28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3356</th>\n",
       "      <td>exit 217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3357</th>\n",
       "      <td>exit 217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3360</th>\n",
       "      <td>exit 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3361</th>\n",
       "      <td>exit 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3362</th>\n",
       "      <td>exit 261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3366</th>\n",
       "      <td>exit 49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3367</th>\n",
       "      <td>exit 49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3369</th>\n",
       "      <td>exit 261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3370</th>\n",
       "      <td>exit 261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3371</th>\n",
       "      <td>exit 213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3372</th>\n",
       "      <td>exit 19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373</th>\n",
       "      <td>exit 213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3375</th>\n",
       "      <td>exit 44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3376</th>\n",
       "      <td>exit 44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3377</th>\n",
       "      <td>exit 44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3378</th>\n",
       "      <td>exit 44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3379</th>\n",
       "      <td>exit 44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3380</th>\n",
       "      <td>exit 44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3381</th>\n",
       "      <td>exit 256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3382</th>\n",
       "      <td>exit 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3385</th>\n",
       "      <td>exit 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3403</th>\n",
       "      <td>exit 205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3405</th>\n",
       "      <td>exit 205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3407</th>\n",
       "      <td>exit 205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>exit 205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3417</th>\n",
       "      <td>exit 80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>exit 80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>exit 80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>exit 80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3439</th>\n",
       "      <td>exit 191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1101 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     exit_list\n",
       "5     exit 10a\n",
       "6     exit 10a\n",
       "10     exit 12\n",
       "11    exit 152\n",
       "12     exit 12\n",
       "14     exit 45\n",
       "15    exit 152\n",
       "17     exit 45\n",
       "20    exit 10a\n",
       "21     exit 13\n",
       "22     exit 13\n",
       "41     exit 45\n",
       "42     exit 45\n",
       "44    exit 10a\n",
       "59    exit 174\n",
       "67     exit 17\n",
       "72    exit 120\n",
       "74     exit 13\n",
       "75     exit 12\n",
       "79     exit 12\n",
       "82    exit 166\n",
       "83    exit 166\n",
       "98     exit 17\n",
       "101   exit 130\n",
       "107    exit 45\n",
       "109    exit 22\n",
       "110    exit 22\n",
       "111    exit 28\n",
       "112    exit 28\n",
       "113    exit 28\n",
       "...        ...\n",
       "3356  exit 217\n",
       "3357  exit 217\n",
       "3360   exit 17\n",
       "3361   exit 17\n",
       "3362  exit 261\n",
       "3366   exit 49\n",
       "3367   exit 49\n",
       "3369  exit 261\n",
       "3370  exit 261\n",
       "3371  exit 213\n",
       "3372   exit 19\n",
       "3373  exit 213\n",
       "3375   exit 44\n",
       "3376   exit 44\n",
       "3377   exit 44\n",
       "3378   exit 44\n",
       "3379   exit 44\n",
       "3380   exit 44\n",
       "3381  exit 256\n",
       "3382   exit 21\n",
       "3385   exit 20\n",
       "3403  exit 205\n",
       "3405  exit 205\n",
       "3407  exit 205\n",
       "3408  exit 205\n",
       "3417   exit 80\n",
       "3418   exit 80\n",
       "3419   exit 80\n",
       "3420   exit 80\n",
       "3439  exit 191\n",
       "\n",
       "[1101 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "michael_exits[(michael_exits[\"exit_list\"] != \"None\") & (\"exit\" not in michael_df[\"text\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "michael_exits.to_csv(\"../Data/michael_exits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "florence_exits = add_exit_lists(florence_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "florence_exits.to_csv(\"../Data/florence_exits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exit_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>exit 276,exit 285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>exit 81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>exit 328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>exit 98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>exit 81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>exit 328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>exit 81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>exit 328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>exit 81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>exit 328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>exit 328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>exit 183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>exit 81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>exit 328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>exit 419,exit 423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>exit 81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>exit 328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>exit 298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>exit 287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>exit 81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>exit 328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>exit 328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>exit 4,exit 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>exit 328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>exit 328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>exit 328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>exit 328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>exit 334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>exit 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>exit 178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>exit 42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>exit 219a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>exit 42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>exit 187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>exit 187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>exit 33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>exit 33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>exit 33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>exit 172a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>exit 33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>exit 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>exit 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>exit 23a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>exit 24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>exit 24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>exit 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>exit 23a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>exit 33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>exit 18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>exit 23a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>exit 98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>exit 18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>exit 23a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>exit 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>exit 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>exit 28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>exit 28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>exit 154a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>exit 154a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>exit 8,exit 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>544 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              exit_list\n",
       "383   exit 276,exit 285\n",
       "385             exit 81\n",
       "386            exit 328\n",
       "387             exit 98\n",
       "402             exit 81\n",
       "403            exit 328\n",
       "416             exit 81\n",
       "417            exit 328\n",
       "422             exit 81\n",
       "423            exit 328\n",
       "430            exit 328\n",
       "431            exit 183\n",
       "443             exit 81\n",
       "444            exit 328\n",
       "446   exit 419,exit 423\n",
       "455             exit 81\n",
       "456            exit 328\n",
       "462            exit 298\n",
       "463            exit 287\n",
       "466             exit 81\n",
       "467            exit 328\n",
       "484            exit 328\n",
       "486      exit 4,exit 11\n",
       "487            exit 328\n",
       "497            exit 328\n",
       "527            exit 328\n",
       "549            exit 328\n",
       "571            exit 334\n",
       "581              exit 2\n",
       "582            exit 178\n",
       "...                 ...\n",
       "1167            exit 42\n",
       "1168          exit 219a\n",
       "1169            exit 42\n",
       "1170           exit 187\n",
       "1171           exit 187\n",
       "1172            exit 33\n",
       "1173            exit 33\n",
       "1174            exit 33\n",
       "1175          exit 172a\n",
       "1176            exit 33\n",
       "1177            exit 20\n",
       "1178            exit 20\n",
       "1180           exit 23a\n",
       "1181            exit 24\n",
       "1183            exit 24\n",
       "1186             exit 5\n",
       "1187           exit 23a\n",
       "1188            exit 33\n",
       "1189            exit 18\n",
       "1190           exit 23a\n",
       "1191            exit 98\n",
       "1192            exit 18\n",
       "1193           exit 23a\n",
       "1194             exit 5\n",
       "1195             exit 5\n",
       "1196            exit 28\n",
       "1197            exit 28\n",
       "1198          exit 154a\n",
       "1199          exit 154a\n",
       "1200      exit 8,exit 5\n",
       "\n",
       "[544 rows x 1 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "florence_exits[florence_exits[\"exit_list\"] != \"None\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for mile markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mile_marker_search(text):\n",
    "    words = text.split()\n",
    "    exit_string = \"\"\n",
    "    exit_list = []\n",
    "    for i in range(len(words)):\n",
    "        string = \"\"\n",
    "        if(((words[i] == \"mile marker\") |  (words[i] == \"mm\")) &\n",
    "           (i < len(words) - 1)):\n",
    "            try:\n",
    "                float(words[i+1][0])\n",
    "                string = \"mile marker \" + words[i+1]\n",
    "            except:\n",
    "                pass\n",
    "        elif((\"mile marker\" in words[i]) & (words[i].find(\"mile marker\") == 0)):\n",
    "            num_check = words[i].replace(\"mile marker\", \"\")\n",
    "            try:\n",
    "                float(num_check[0])\n",
    "                string = \"mile marker \" + num_check \n",
    "            except:\n",
    "                pass\n",
    "        elif((\"mm\" in words[i]) & (words[i].find(\"mm\") == 0)):\n",
    "            num_check = words[i].replace(\"mm\", \"\")\n",
    "            try:\n",
    "                float(num_check[0])\n",
    "                string = \"mile marker \" + num_check \n",
    "            except:\n",
    "                pass\n",
    "        if string != \"\":\n",
    "            exit_list.append(string)\n",
    "    return string_from_list(exit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mm_lists(df):\n",
    "    mm_df = pd.DataFrame()\n",
    "    for row in df.index:\n",
    "        text = df.loc[row, \"text\"]\n",
    "        mm_df.loc[row, \"mm_list\"] = mile_marker_search(text)\n",
    "    return mm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvey_mm = add_mm_lists(harvey_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mm_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>mile marker 16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mm_list\n",
       "867  mile marker 16"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harvey_mm[(harvey_mm[\"mm_list\"] != \"None\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvey_mm.to_csv(\"../Data/harvey_mm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "michael_mm = add_mm_lists(michael_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mm_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mile marker 88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mile marker 88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mile marker 88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mile marker 121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mile marker 49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mile marker 49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mile marker 49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mile marker 49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mile marker 153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mile marker 153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mile marker 122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mile marker 171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>mile marker 126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>mile marker 150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>mile marker 151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>mile marker 50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>mile marker 49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>mile marker 150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>mile marker 151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>mile marker 49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>mile marker 47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>mile marker 50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>mile marker 50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>mile marker 50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>mile marker 47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>mile marker 151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>mile marker 49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>mile marker 47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>mile marker 150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>mile marker 185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3205</th>\n",
       "      <td>mile marker 330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3206</th>\n",
       "      <td>mile marker 36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208</th>\n",
       "      <td>mile marker 36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>mile marker 72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>mile marker 334,mile marker 336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3227</th>\n",
       "      <td>mile marker 334,mile marker 336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>mile marker 334,mile marker 336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>mile marker 89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>mile marker 66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>mile marker 66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3255</th>\n",
       "      <td>mile marker 36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>mile marker 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>mile marker 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>mile marker 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>mile marker 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>mile marker 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>mile marker 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>mile marker 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>mile marker 36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>mile marker 188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>mile marker 76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3281</th>\n",
       "      <td>mile marker 273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3282</th>\n",
       "      <td>mile marker 305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3301</th>\n",
       "      <td>mile marker 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3302</th>\n",
       "      <td>mile marker 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3326</th>\n",
       "      <td>mile marker 262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3327</th>\n",
       "      <td>mile marker 262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3333</th>\n",
       "      <td>mile marker 304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3388</th>\n",
       "      <td>mile marker 54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3410</th>\n",
       "      <td>mile marker 203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              mm_list\n",
       "1                      mile marker 88\n",
       "2                      mile marker 88\n",
       "3                      mile marker 88\n",
       "7                     mile marker 121\n",
       "8                      mile marker 49\n",
       "9                      mile marker 49\n",
       "13                     mile marker 49\n",
       "16                     mile marker 49\n",
       "18                    mile marker 153\n",
       "19                    mile marker 153\n",
       "24                    mile marker 122\n",
       "26                    mile marker 171\n",
       "27                    mile marker 126\n",
       "28                    mile marker 150\n",
       "29                    mile marker 151\n",
       "30                     mile marker 50\n",
       "31                     mile marker 49\n",
       "33                    mile marker 150\n",
       "34                    mile marker 151\n",
       "35                     mile marker 49\n",
       "36                     mile marker 47\n",
       "37                     mile marker 50\n",
       "38                     mile marker 50\n",
       "39                     mile marker 50\n",
       "40                     mile marker 47\n",
       "45                    mile marker 151\n",
       "46                     mile marker 49\n",
       "47                     mile marker 47\n",
       "48                    mile marker 150\n",
       "51                    mile marker 185\n",
       "...                               ...\n",
       "3205                  mile marker 330\n",
       "3206                   mile marker 36\n",
       "3208                   mile marker 36\n",
       "3212                   mile marker 72\n",
       "3222  mile marker 334,mile marker 336\n",
       "3227  mile marker 334,mile marker 336\n",
       "3230  mile marker 334,mile marker 336\n",
       "3231                   mile marker 89\n",
       "3245                   mile marker 66\n",
       "3246                   mile marker 66\n",
       "3255                   mile marker 36\n",
       "3257                   mile marker 25\n",
       "3258                   mile marker 25\n",
       "3259                    mile marker 9\n",
       "3261                   mile marker 25\n",
       "3262                    mile marker 9\n",
       "3263                    mile marker 9\n",
       "3264                   mile marker 25\n",
       "3267                   mile marker 36\n",
       "3273                  mile marker 188\n",
       "3277                   mile marker 76\n",
       "3281                  mile marker 273\n",
       "3282                  mile marker 305\n",
       "3301                    mile marker 4\n",
       "3302                    mile marker 4\n",
       "3326                  mile marker 262\n",
       "3327                  mile marker 262\n",
       "3333                  mile marker 304\n",
       "3388                   mile marker 54\n",
       "3410                  mile marker 203\n",
       "\n",
       "[768 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "michael_mm[(michael_mm[\"mm_list\"] != \"None\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "michael_mm.to_csv(\"../Data/michael_mm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "florence_mm = add_mm_lists(florence_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mm_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>mile marker 286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>mile marker 294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>mile marker 286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>mile marker 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>mile marker 105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>mile marker 105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>mile marker 98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>mile marker 98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>mile marker 436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>mile marker 436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>mile marker 98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>mile marker 269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>mile marker 226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>mile marker 293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>mile marker 24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>mile marker 284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>mile marker 57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>mile marker 60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>mile marker 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>mile marker 293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>mile marker 285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>mile marker 270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>mile marker 290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>mile marker 279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>mile marker 279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>mile marker 279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>mile marker 290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>mile marker 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>mile marker 173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>mile marker 183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>mile marker 273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>mile marker 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>mile marker 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>mile marker 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>mile marker 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>mile marker 283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>mile marker 319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>mile marker 336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>mile marker 325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>mile marker 292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>mile marker 178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>mile marker 300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>mile marker 306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>mile marker 67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>mile marker 423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>mile marker 26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>mile marker 13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>mile marker 99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>mile marker 309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>mile marker 312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>mile marker 312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>mile marker 436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>mile marker 436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>mile marker 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>mile marker 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>mile marker 300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>mile marker 303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>mile marker 287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>mile marker 287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>mile marker 100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             mm_list\n",
       "77   mile marker 286\n",
       "78   mile marker 294\n",
       "79   mile marker 286\n",
       "81   mile marker 100\n",
       "82   mile marker 105\n",
       "83   mile marker 105\n",
       "84    mile marker 98\n",
       "85    mile marker 98\n",
       "86   mile marker 436\n",
       "87   mile marker 436\n",
       "88    mile marker 98\n",
       "90   mile marker 269\n",
       "91   mile marker 226\n",
       "94   mile marker 293\n",
       "95    mile marker 24\n",
       "97   mile marker 284\n",
       "100   mile marker 57\n",
       "101   mile marker 60\n",
       "102   mile marker 59\n",
       "106  mile marker 293\n",
       "108  mile marker 285\n",
       "109  mile marker 270\n",
       "110  mile marker 290\n",
       "112  mile marker 279\n",
       "113  mile marker 279\n",
       "114  mile marker 279\n",
       "115  mile marker 290\n",
       "116    mile marker 9\n",
       "118  mile marker 173\n",
       "119  mile marker 183\n",
       "..               ...\n",
       "306  mile marker 273\n",
       "307    mile marker 9\n",
       "312    mile marker 1\n",
       "314    mile marker 7\n",
       "315    mile marker 7\n",
       "316  mile marker 283\n",
       "319  mile marker 319\n",
       "322  mile marker 336\n",
       "324  mile marker 325\n",
       "340  mile marker 292\n",
       "342  mile marker 178\n",
       "344  mile marker 300\n",
       "354  mile marker 306\n",
       "360   mile marker 67\n",
       "364  mile marker 423\n",
       "365   mile marker 26\n",
       "366   mile marker 13\n",
       "367   mile marker 99\n",
       "368  mile marker 309\n",
       "369  mile marker 312\n",
       "370  mile marker 312\n",
       "372  mile marker 436\n",
       "373  mile marker 436\n",
       "374   mile marker 12\n",
       "376   mile marker 12\n",
       "378  mile marker 300\n",
       "379  mile marker 303\n",
       "380  mile marker 287\n",
       "381  mile marker 287\n",
       "382  mile marker 100\n",
       "\n",
       "[138 rows x 1 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "florence_mm[(florence_mm[\"mm_list\"] != \"None\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "florence_mm.to_csv(\"../Data/florence_mm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Main Interstate Highways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "interstate_df = pd.read_csv(\"../Data/Interstate_List.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "interstate_list = list(set(interstate_df[\"Interstate Highway\"].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "interstate_dict = {}\n",
    "for interstate in interstate_list:\n",
    "    interstate_dict[interstate] = {\"states\" : interstate_df[interstate_df[\"Interstate Highway\"] == interstate][\"State\"].to_list(),\n",
    "                                   \"names\" : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for roads, values in interstate_dict.items():\n",
    "    lst = []\n",
    "    lower = roads.lower()\n",
    "    space = lower.replace(\"-\", \" \")\n",
    "    remove = lower.replace(\"-\", \"\")\n",
    "    lst.append(lower)\n",
    "    lst.append(space)\n",
    "    lst.append(remove)\n",
    "    base_list = [lower, space, remove]\n",
    "    replacements = [{\"i\" : \"interstate\"},\n",
    "                    {\"ih\" : \"interstate\"}]\n",
    "    for dicts in replacements:\n",
    "        keys = list(dicts.keys())[0]\n",
    "        values = list(dicts.values())[0]\n",
    "        for bases in base_list:\n",
    "            lst.append(bases.replace(keys, values))\n",
    "    interstate_dict[roads][\"names\"] = lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_interstates(state, i_dict):\n",
    "    new_dict = {}\n",
    "    for roads, values in i_dict.items():\n",
    "        if(state in i_dict[roads][\"states\"]):\n",
    "            new_dict[roads] = i_dict[roads][\"names\"]\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "virginia_interstates = get_state_interstates(\"Virginia\", interstate_dict)\n",
    "texas_interstates = get_state_interstates(\"Texas\", interstate_dict)\n",
    "ncarolina_interstates = get_state_interstates(\"North Carolina\", interstate_dict)\n",
    "scarolina_interstates = get_state_interstates(\"South Carolina\", interstate_dict)\n",
    "florida_interstates = get_state_interstates(\"Florida\", interstate_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Interstate Roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_df = pd.read_csv(\"../Data/Auxiliary_List.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_list = list(set(aux_df[\"Interstate Route\"].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for aux_routes in aux_list:\n",
    "    aux_dict[aux_routes] = {\"states\" : [], \"names\" : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for highways, values in aux_dict.items():\n",
    "    values[\"states\"] = aux_df[aux_df[\"Interstate Route\"] == highways][\"State\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for roads, values in aux_dict.items():\n",
    "    lst = []\n",
    "    lower = roads.lower()\n",
    "    space = lower.replace(\"-\", \" \")\n",
    "    remove = lower.replace(\"-\", \"\")\n",
    "    lst.append(lower)\n",
    "    lst.append(space)\n",
    "    lst.append(remove)\n",
    "    base_list = [lower, space, remove]\n",
    "    replacements = [{\"i\" : \"interstate\"},\n",
    "                   {\"ih\" : \"interstate\"}]\n",
    "    for dicts in replacements:\n",
    "        keys = list(dicts.keys())[0]\n",
    "        values = list(dicts.values())[0]\n",
    "        for bases in base_list:\n",
    "            lst.append(bases.replace(keys, values))\n",
    "    aux_dict[roads][\"names\"] = lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "virginia_aux = get_state_interstates(\"Virginia\", aux_dict)\n",
    "ncarolina_aux = get_state_interstates(\"North Carolina\", aux_dict)\n",
    "scarolina_aux = get_state_interstates(\"South Carolina\", aux_dict)\n",
    "florida_aux = get_state_interstates(\"Florida\", aux_dict)\n",
    "texas_aux = get_state_interstates(\"Texas\", aux_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## US Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "us_routes_df = pd.read_csv(\"../Data/US_Routes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_routes_dict = {}\n",
    "for roads in us_routes_df.index:\n",
    "    us_routes_dict[us_routes_df.loc[roads, \"US Routes\"]] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for roads in us_routes_df.index:\n",
    "    name = us_routes_df.loc[roads, \"US Routes\"]\n",
    "    lst = []\n",
    "    lower = name.lower()\n",
    "    dash = lower.replace(\" \", \"-\")\n",
    "    remove = lower.replace(\" \", \"\")\n",
    "    lst.append(lower)\n",
    "    lst.append(dash)\n",
    "    lst.append(remove)\n",
    "    base_list = [lower, dash, remove]\n",
    "    replacements = [{\"us\" : \"u.s.\"},\n",
    "                   {\"us\" : \"us route\"},\n",
    "                   {\"us\" : \"u.s. route\"},\n",
    "                   {\"us\" : \"us rte\"},\n",
    "                   {\"us\" : \"u.s. rte\"},\n",
    "                   {\"us\" : \"us-route\"},\n",
    "                   {\"us\" : \"u.s.-route\"},\n",
    "                   {\"us\" : \"us-rte\"},\n",
    "                   {\"us\" : \"u.s.-rte\"}]\n",
    "    for dicts in replacements:\n",
    "        keys = list(dicts.keys())[0]\n",
    "        values = list(dicts.values())[0]\n",
    "        for bases in base_list:\n",
    "            lst.append(bases.replace(keys, values))\n",
    "    us_routes_dict[name] = lst    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_roads_df = pd.read_csv(\"../Data/State_Road_List.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "texas_roads_df = state_roads_df[state_roads_df[\"State\"] == \"Texas\"][[\"Road Type\", \"Name\"]]\n",
    "ncarolina_roads_df = state_roads_df[state_roads_df[\"State\"] == \"North Carolina\"][[\"Road Type\", \"Name\"]]\n",
    "scarolina_roads_df = state_roads_df[state_roads_df[\"State\"] == \"South Carolina\"][[\"Road Type\", \"Name\"]]\n",
    "florida_roads_df = state_roads_df[state_roads_df[\"State\"] == \"Florida\"][[\"Road Type\", \"Name\"]]\n",
    "virginia_roads_df = state_roads_df[state_roads_df[\"State\"] == \"Virginia\"][[\"Road Type\", \"Name\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionaries for each state that contain state roads as keys and list \"names\" to be populated with alternative spellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "texas_roads_dict = {}\n",
    "for roads in texas_roads_df.index:\n",
    "    texas_roads_dict[texas_roads_df.loc[roads, \"Name\"]] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncarolina_roads_dict = {}\n",
    "for roads in ncarolina_roads_df.index:\n",
    "    ncarolina_roads_dict[ncarolina_roads_df.loc[roads, \"Name\"]] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarolina_roads_dict = {}\n",
    "for roads in scarolina_roads_df.index:\n",
    "    scarolina_roads_dict[scarolina_roads_df.loc[roads, \"Name\"]] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "florida_roads_dict = {}\n",
    "for roads in florida_roads_df.index:\n",
    "    florida_roads_dict[florida_roads_df.loc[roads, \"Name\"]] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "virginia_roads_dict = {}\n",
    "for roads in virginia_roads_df.index:\n",
    "    virginia_roads_dict[virginia_roads_df.loc[roads, \"Name\"]] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list of alternative highway/road spellings for each state highway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for roads in texas_roads_df.index:\n",
    "    name = texas_roads_df.loc[roads, \"Name\"]\n",
    "    road_type = texas_roads_df.loc[roads, \"Road Type\"]\n",
    "    lst = []\n",
    "    lower = name.lower()\n",
    "    dash = lower.replace(\" \", \"-\")\n",
    "    remove = lower.replace(\" \", \"\")\n",
    "    lst.append(lower)\n",
    "    lst.append(dash)\n",
    "    lst.append(remove)\n",
    "    base_list = [lower, dash, remove]\n",
    "    if(road_type == \"State Highway\"):\n",
    "        for abbrevs in suffix_dict[\"HIGHWAY\"]:\n",
    "            lst.append(lower.replace(\"sh\", \"state \" + abbrevs.lower()))\n",
    "            lst.append(lower.replace(\"sh\", \"st \" + abbrevs.lower()))\n",
    "            lst.append(dash.replace(\"sh\", \"state \" + abbrevs.lower()))\n",
    "            lst.append(dash.replace(\"sh\", \"st \" + abbrevs.lower()))\n",
    "            lst.append(remove.replace(\"sh\", \"state \" + abbrevs.lower()))\n",
    "            lst.append(remove.replace(\"sh\", \"st \" + abbrevs.lower()))\n",
    "            lst.append(lower.replace(\"sh\", \"state \" + abbrevs.lower() + \"s\"))\n",
    "            lst.append(lower.replace(\"sh\", \"st \" + abbrevs.lower() + \"s\"))\n",
    "            lst.append(dash.replace(\"sh\", \"state \" + abbrevs.lower() + \"s\"))\n",
    "            lst.append(dash.replace(\"sh\", \"st \" + abbrevs.lower() + \"s\"))\n",
    "            lst.append(remove.replace(\"sh\", \"state \" + abbrevs.lower() + \"s\"))\n",
    "            lst.append(remove.replace(\"sh\", \"st \" + abbrevs.lower() + \"s\"))\n",
    "    replacements = [{\"loop\" : \"sl\"},\n",
    "                    {\"loop\" : \"lp\"},\n",
    "                    {\"fm\" : \"farm to market\"},\n",
    "                    {\"fm\" : \"farm-to-market\"},\n",
    "                    {\"fm\" : \"farm to market road\"},\n",
    "                    {\"fm\" : \"farm-to-market road\"},\n",
    "                    {\"fm\" : \"farm to market roads\"},\n",
    "                    {\"fm\" : \"farm-to-market roads\"},\n",
    "                    {\"pr\" : \"park road\"},\n",
    "                    {\"recreational road\" : \"re\"},\n",
    "                    {\"recreational road\" : \"recreational roads\"},\n",
    "                    {\"ranch road\" : \"rr\"}]\n",
    "    for dicts in replacements:\n",
    "        keys = list(dicts.keys())[0]\n",
    "        values = list(dicts.values())[0]\n",
    "        for bases in base_list:\n",
    "            lst.append(bases.replace(keys, values))\n",
    "    texas_roads_dict[name] = lst    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for roads in ncarolina_roads_df.index:\n",
    "    name = ncarolina_roads_df.loc[roads, \"Name\"]\n",
    "    road_type = ncarolina_roads_df.loc[roads, \"Road Type\"]\n",
    "    lst = []\n",
    "    lower = name.lower()\n",
    "    dash = lower.replace(\" \", \"-\")\n",
    "    remove = lower.replace(\" \", \"\")\n",
    "    lst.append(lower)\n",
    "    lst.append(dash)\n",
    "    lst.append(remove)\n",
    "    base_list = [lower, dash, remove]\n",
    "    for abbrevs in suffix_dict[\"HIGHWAY\"]:\n",
    "        for bases in base_list:\n",
    "            lst.append(bases.replace(\"nc\", abbrevs))\n",
    "    ncarolina_roads_dict[name] = lst    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for roads in scarolina_roads_df.index:\n",
    "    name = scarolina_roads_df.loc[roads, \"Name\"]\n",
    "    road_type = scarolina_roads_df.loc[roads, \"Road Type\"]\n",
    "    lst = []\n",
    "    lower = name.lower()\n",
    "    dash = lower.replace(\" \", \"-\")\n",
    "    remove = lower.replace(\" \", \"\")\n",
    "    lst.append(lower)\n",
    "    lst.append(dash)\n",
    "    lst.append(remove)\n",
    "    base_list = [lower, dash, remove]\n",
    "    for abbrevs in suffix_dict[\"HIGHWAY\"]:\n",
    "        for bases in base_list:\n",
    "            lst.append(bases.replace(\"sc\", abbrevs))\n",
    "    scarolina_roads_dict[name] = lst    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for roads in virginia_roads_df.index:\n",
    "    name = virginia_roads_df.loc[roads, \"Name\"]\n",
    "    road_type = virginia_roads_df.loc[roads, \"Road Type\"]\n",
    "    lst = []\n",
    "    lower = name.lower()\n",
    "    dash = lower.replace(\" \", \"-\")\n",
    "    remove = lower.replace(\" \", \"\")\n",
    "    lst.append(lower)\n",
    "    lst.append(dash)\n",
    "    lst.append(remove)\n",
    "    base_list = [lower, dash, remove]\n",
    "    for bases in base_list:\n",
    "        lst.append(bases.replace(\"sr\", \"state route\"))\n",
    "        lst.append(bases.replace(\"sr\", \"st route\"))\n",
    "        lst.append(bases.replace(\"sr\", \"state rte\"))\n",
    "        lst.append(bases.replace(\"sr\", \"st rte \"))\n",
    "    virginia_roads_dict[name] = lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for roads in florida_roads_df.index:\n",
    "    name = florida_roads_df.loc[roads, \"Name\"]\n",
    "    road_type = florida_roads_df.loc[roads, \"Road Type\"]\n",
    "    lst = []\n",
    "    lower = name.lower()\n",
    "    dash = lower.replace(\" \", \"-\")\n",
    "    remove = lower.replace(\" \", \"\")\n",
    "    lst.append(lower)\n",
    "    lst.append(dash)\n",
    "    lst.append(remove)\n",
    "    base_list = [lower, dash, remove]\n",
    "    replacements = [{\"sr\" : \"state road\"},\n",
    "                    {\"sr\" : \"state rd\"},\n",
    "                    {\"sr\" : \"st road\"},\n",
    "                    {\"sr\" : \"st rd\"},\n",
    "                    {\"causeway\" : \"causwa\"},\n",
    "                    {\"causeway\" : \"cswy\"},\n",
    "                    {\"bridge\" : \"brdge\"},\n",
    "                    {\"bridge\" : \"brg\"},\n",
    "                   {\"road\" : \"rd\"},\n",
    "                   {\"expresway\" : \"exp\"},\n",
    "                   {\"expresway\" : \"expr\"},\n",
    "                   {\"expresway\" : \"express\"},\n",
    "                   {\"expresway\" : \"expw\"},\n",
    "                   {\"expresway\" : \"expy\"}]\n",
    "    for dicts in replacements:\n",
    "        keys = list(dicts.keys())[0]\n",
    "        values = list(dicts.values())[0]\n",
    "        for bases in base_list:\n",
    "            lst.append(bases.replace(keys, values))\n",
    "    florida_roads_dict[name] = lst    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary containing a list of roads relevant to each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_road_dict = {\"Florida\" : [florida_interstates, florida_aux, us_routes_dict, florida_roads_dict],\n",
    "                   \"Virginia\" : [virginia_interstates, virginia_aux, us_routes_dict, virginia_roads_dict],\n",
    "                   \"North Carolina\" : [ncarolina_interstates, ncarolina_aux, us_routes_dict, ncarolina_roads_dict],\n",
    "                   \"South Carolina\" : [scarolina_interstates, scarolina_aux, us_routes_dict, scarolina_roads_dict],\n",
    "                   \"Texas\" : [texas_interstates, texas_aux, us_routes_dict, texas_roads_dict]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to check for presence of road in string\n",
    "This function iterates through text to create list of all roads that are found in the string, and returns a dataframe that contains 3 columns:\n",
    "\n",
    "    1) name of the road\n",
    "    2) which word the road is contained within (when text is split into words by a space)\n",
    "    3) index position of the road within the word\n",
    "\n",
    "Roads that are substrings of other roads are removed, but roads that appear more than once in separate parts of the text are not removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_roads(state, text):\n",
    "# Create variables including dictionary of roads to search over, a list of words in each tweet,\n",
    "# and lists to track the presence of roads inside text\n",
    "    state_roads = master_road_dict[state]\n",
    "    words = text.split()\n",
    "    relevant_roads = []\n",
    "    road_list_position = []\n",
    "    road_substring_indices = []\n",
    "    index_tracker = 0\n",
    "# Loop over the dictionary of roads to check if that road is present in the tweet, and keep track of its relative position \n",
    "# within the tweet\n",
    "    for dicts in state_roads:\n",
    "        for road, abbrevs in dicts.items():\n",
    "            for abbrev in abbrevs:\n",
    "                for i in range(len(words)):\n",
    "                    if((abbrev in words[i]) & (road not in relevant_roads)):\n",
    "                        relevant_roads.append(road)\n",
    "                        road_substring_indices.append(words[i].find(abbrev))\n",
    "                        road_list_position.append(i)\n",
    "    \n",
    "# Loop over newly created list of roads found within the tweet, and delete any roads that are a substring of another road.\n",
    "# For instance, US-10 should only return US-10 and exclude US-1 even though US-1 is found within US-10.\n",
    "# First, a list of indices to delete is created - first set of loops. Then, new lists are created where only those not to be\n",
    "# deleted are added - second loop\n",
    "\n",
    "# First loop\n",
    "    delete_list = []\n",
    "    for i in range(len(relevant_roads)):\n",
    "        for j in range(len(relevant_roads)):\n",
    "            if ((i != j) &\n",
    "                (j not in delete_list) &\n",
    "                (road_substring_indices[i] == road_substring_indices[j]) &\n",
    "                (road_list_position[i] == road_list_position[j]) &\n",
    "                (len(relevant_roads[j]) < len(relevant_roads[i]))):\n",
    "                delete_list.append(j)\n",
    "# New lists\n",
    "    clean_relevant_roads = []\n",
    "    clean_road_substring_indices = []\n",
    "    clean_road_list_position = []\n",
    "# Second loop\n",
    "    for i in range(len(relevant_roads)):\n",
    "        if i not in delete_list:\n",
    "            clean_relevant_roads.append(relevant_roads[i])\n",
    "            clean_road_substring_indices.append(road_substring_indices[i])\n",
    "            clean_road_list_position.append(road_list_position[i])\n",
    "# Create dataframe such that 1) all lists can be sorted in the same way\n",
    "# and 2) to calculate the overall positioning of a found road within the tweet as a combination of:\n",
    "# a) which word the road was found in and b) its index within the word.\n",
    "# This accounts for typos where spaces are not used in between words.\n",
    "# For instance, in the text \"Accident on I-90 between I-93andi-95\", we would want to differentiate the relative position\n",
    "# of i-93 and i-95 within the text, even though both are part of the same word.\n",
    "    roads_df = pd.DataFrame()\n",
    "    roads_df[\"relevant_roads\"] = clean_relevant_roads\n",
    "    roads_df[\"road_substring_indices\"] = clean_road_substring_indices\n",
    "    roads_df[\"road_list_position\"] = clean_road_list_position\n",
    "    roads_df = roads_df.sort_values(by=[\"road_list_position\", \"road_substring_indices\"])\n",
    "    roads_df = roads_df.reset_index(drop=True)\n",
    "    roads_df[\"overall_road_position\"] = roads_df.index + 1\n",
    "# After getting values as a dataframe for each text, below code and use of above function\n",
    "# takes each series and converts to a list such that text can be stored inside of a dataframe containing many tweets\n",
    "    roads_string = string_from_list(roads_df[\"relevant_roads\"])\n",
    "    roads_order = string_from_list(roads_df[\"overall_road_position\"])\n",
    "    has_road = 1 if roads_string != \"None\" else 0\n",
    "    num_roads = roads_df[\"relevant_roads\"].size\n",
    "    return [roads_string, roads_order, has_road, num_roads]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cities Towns and Counties Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_list = pd.read_csv(\"../Data/Cities_List.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties_list = pd.read_csv(\"../Data/us_counties.csv\",  encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cities_list[\"City\"] = cities_list[\"City\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties_list[\"County or equivalent\"] = counties_list[\"County or equivalent\"].str.lower()\n",
    "relevant_counties = counties_list[(counties_list[\"State or district\"] == \"Virginia\") |\n",
    "                                   (counties_list[\"State or district\"] == \"North Carolina\") |\n",
    "                                  (counties_list[\"State or district\"] == \"South Carolina\") |\n",
    "                                  (counties_list[\"State or district\"] == \"Florida\") |\n",
    "                                  (counties_list[\"State or district\"] == \"Texas\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_list = list(set(relevant_counties[\"State or district\"].to_list()))\n",
    "state_areas_dict = {}\n",
    "for state in state_list:\n",
    "    state_areas_dict[state] = {\"counties\" : {},\n",
    "                               \"cities\" : {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in state_list:\n",
    "    counties = relevant_counties[relevant_counties[\"State or district\"] == state][\"County or equivalent\"]\n",
    "    cities = cities_list[cities_list[\"State\"] == state][\"City\"]\n",
    "    for county in counties:\n",
    "        state_areas_dict[state][\"counties\"][county] = [county,\n",
    "                                                       county.replace(\"county\", \"cty\"),\n",
    "                                                       county.replace(\"county\", \"cnty\"),\n",
    "                                                       county.replace(\"county\", \"co\"),\n",
    "                                                       county.replace(\" county\", \"county\"),\n",
    "                                                       county.replace(\" county\", \"cty\"),\n",
    "                                                       county.replace(\" county\", \"cnty\"),\n",
    "                                                       county.replace(\" county\", \"co\")]\n",
    "    for city in cities:\n",
    "        state_areas_dict[state][\"cities\"][city] = [city]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_city_county(state, state_areas_dict, text, area_type):\n",
    "    areas_list = []\n",
    "    areas_list_position = []\n",
    "    areas_substring_indices = []\n",
    "    words = text.split()\n",
    "    for area in state_areas_dict[state][area_type]:\n",
    "        for abbrev in state_areas_dict[state][area_type][area]:\n",
    "            for i in range(len(words)):\n",
    "                if ((abbrev in words[i]) & (area not in areas_list)):\n",
    "                    areas_list.append(area)\n",
    "                    areas_list_position.append(i)\n",
    "                    areas_substring_indices.append(words[i].find(abbrev))\n",
    "    areas_df = pd.DataFrame()\n",
    "    areas_df[area_type + \"_list\"] = areas_list\n",
    "    areas_df[area_type + \"_list_position\"] = areas_list_position\n",
    "    areas_df[area_type + \"_substring_indices\"] = areas_substring_indices\n",
    "    areas_df = areas_df.sort_values(by = [area_type + \"_list_position\", area_type + \"_substring_indices\"])\n",
    "    areas_df = areas_df.reset_index(drop=True)\n",
    "    areas_df[\"overall_\" + area_type +\"_position\"] = areas_df.index + 1\n",
    "    \n",
    "    area_string = string_from_list(areas_df[area_type + \"_list\"])\n",
    "    area_order = string_from_list(areas_df[area_type + \"_list_position\"])\n",
    "    has_area = 1 if area_string != \"None\" else 0\n",
    "    num_areas = areas_df[area_type + \"_list\"].size\n",
    "    return [area_string, area_order, has_area, num_areas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add highway, county and city features to new dataframe for each hurricane\n",
    "for each hurricane, features include\n",
    "\n",
    "1) a string that represents a comma separated list of higways found\n",
    "2) order in which highways/cities/counties appear in text\n",
    "3) boolean for whether or not a highway/city/county was found\n",
    "4) number of highways, counties, cities found\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate(df):\n",
    "    new_cols = pd.DataFrame()\n",
    "    num = []\n",
    "    highway_strings = []\n",
    "    highway_orders = []\n",
    "    highway_bools = []\n",
    "    highway_lengths = []\n",
    "    \n",
    "    city_strings = []\n",
    "    city_orders = []\n",
    "    city_bools = []\n",
    "    city_lengths = []\n",
    "    \n",
    "    county_strings = []\n",
    "    county_orders = []\n",
    "    county_bools = []\n",
    "    county_lengths = []    \n",
    "    \n",
    "    for rows in df.index:\n",
    "        state = df.loc[rows,\"state\"]\n",
    "        text = df.loc[rows,\"text\"]\n",
    "        roads_values = check_roads(state, text)\n",
    "        city_values = check_city_county(state, state_areas_dict, text, \"cities\")\n",
    "        county_values = check_city_county(state, state_areas_dict, text, \"counties\")\n",
    "        \n",
    "        highway_strings.append(roads_values[0])\n",
    "        highway_bools.append(roads_values[2])\n",
    "\n",
    "        city_strings.append(city_values[0])\n",
    "        city_bools.append(city_values[2])\n",
    "\n",
    "        county_strings.append(county_values[0])\n",
    "        county_bools.append(county_values[2])\n",
    "        \n",
    "    new_cols[\"highway_string\"] = highway_strings\n",
    "    new_cols[\"has_highway\"] = highway_bools\n",
    "    \n",
    "    new_cols[\"county_string\"] = county_strings\n",
    "    new_cols[\"has_county\"] = county_bools\n",
    "    \n",
    "    new_cols[\"city_string\"] = city_strings\n",
    "    new_cols[\"has_city\"] = city_bools\n",
    "\n",
    "    return new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "annotate(florence_df).to_csv(\"../Data/florence_new_values.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate(harvey_df).to_csv(\"../Data/harvey_new_values.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate(michael_df).to_csv(\"../Data/michael_new_values.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
